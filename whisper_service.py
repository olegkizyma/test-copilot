#!/usr/bin/env python3
"""
ATLAS Whisper Speech Recognition Service
Ð¡ÐµÑ€Ð²Ñ–Ñ Ð´Ð»Ñ Ñ€Ð¾Ð·Ð¿Ñ–Ð·Ð½Ð°Ð²Ð°Ð½Ð½Ñ Ð¼Ð¾Ð²Ð¸ Ð· Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½ÑÐ¼ faster-whisper Large v3
"""

import os
import io
import logging
import tempfile
from datetime import datetime
from pathlib import Path
from flask import Flask, request, jsonify
from flask_cors import CORS
from faster_whisper import WhisperModel

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
)
logger = logging.getLogger('atlas.whisper')

# ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ
WHISPER_PORT = int(os.environ.get('WHISPER_PORT', 3002))
WHISPER_MODEL = 'medium'  # Ð—Ð¼Ñ–Ð½ÑŽÑ”Ð¼Ð¾ Ð½Ð° Ð±Ñ–Ð»ÑŒÑˆ ÑÑ‚Ð°Ð±Ñ–Ð»ÑŒÐ½Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
DEVICE = "auto"  # faster-whisper Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð¾Ð±ÐµÑ€Ðµ Ð½Ð°Ð¹ÐºÑ€Ð°Ñ‰Ð¸Ð¹ Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ñ–Ð¹
COMPUTE_TYPE = "float32"  # Ð”Ð»Ñ ÑÑ‚Ð°Ð±Ñ–Ð»ÑŒÐ½Ð¾ÑÑ‚Ñ– Ð½Ð° Apple Silicon

# Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Flask app
app = Flask(__name__)
CORS(app)

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ– Ð·Ð¼Ñ–Ð½Ð½Ñ– Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ–
whisper_model = None

def is_valid_transcription(text: str, duration: float) -> bool:
    """ÐŸÑ€Ð¾ÑÑ‚Ð° Ð²Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñƒ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ñ–Ñ—.
    Ð’Ñ–Ð´ÑÑ–ÑŽÑ”Ð¼Ð¾ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ–, Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑ– Ð°Ð±Ð¾ Ð¿Ñ–Ð´Ð¾Ð·Ñ€Ñ–Ð»Ñ– Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸.
    """
    try:
        if text is None:
            return False
        t = text.strip()
        if not t:
            return False
        # Ð¯ÐºÑ‰Ð¾ Ð·Ð°Ð¿Ð¸Ñ Ð±ÑƒÐ² Ð²Ñ–Ð´Ð½Ð¾ÑÐ½Ð¾ Ð´Ð¾Ð²Ð³Ð¸Ð¼, Ð° Ñ‚ÐµÐºÑÑ‚ Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ â€” Ð²Ñ–Ð´Ñ„Ñ–Ð»ÑŒÑ‚Ñ€Ð¾Ð²ÑƒÑ”Ð¼Ð¾
        if duration is not None:
            try:
                d = float(duration)
            except Exception:
                d = 0.0
        else:
            d = 0.0
        if d >= 1.0 and len(t) < 3:
            return False
        # Ð’Ñ–Ð´Ñ„Ñ–Ð»ÑŒÑ‚Ñ€ÑƒÐ²Ð°Ñ‚Ð¸ ÑÑƒÑ†Ñ–Ð»ÑŒÐ½Ðµ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñƒ
        if len(set(t)) <= 1:
            return False
        # Ð¯ÐºÑ‰Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾Ð²Ð³Ð¸Ð¹, Ð°Ð»Ðµ ÑÐºÐ»Ð°Ð´Ð°Ñ”Ñ‚ÑŒÑÑ Ð¼Ð°Ð¹Ð¶Ðµ Ð½Ðµ Ð· Ð»Ñ–Ñ‚ÐµÑ€ â€” Ð¿Ñ–Ð´Ð¾Ð·Ñ€Ñ–Ð»Ð¾
        if len(t) >= 10:
            letters = sum(1 for ch in t if ch.isalpha())
            if letters / max(1, len(t)) < 0.3:
                return False
        return True
    except Exception:
        # Ð£ Ð²Ð¸Ð¿Ð°Ð´ÐºÑƒ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸ Ð² Ð²Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ— â€” ÐºÑ€Ð°Ñ‰Ðµ Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ñ‚ÐµÐºÑÑ‚
        return True

def load_whisper_model():
    """Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– faster-whisper Large v3"""
    global whisper_model
    
    if whisper_model is not None:
        return whisper_model
    
    logger.info(f"ðŸ¤– Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ faster-whisper {WHISPER_MODEL} Ð¼Ð¾Ð´ÐµÐ»Ñ–...")
    logger.info(f"Device: {DEVICE}, Compute type: {COMPUTE_TYPE}")
    start_time = datetime.now()
    
    try:
        # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ”Ð¼Ð¾ Large v3 Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        whisper_model = WhisperModel(
            WHISPER_MODEL,
            device=DEVICE,
            compute_type=COMPUTE_TYPE,
            download_root=None,  # Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñƒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ
            local_files_only=False
        )
        
        load_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"âœ… faster-whisper {WHISPER_MODEL} Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð° ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð·Ð° {load_time:.2f} ÑÐµÐºÑƒÐ½Ð´!")
        
        return whisper_model
        
    except Exception as e:
        logger.error(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ–: {e}")
        
        # Fallback Ð´Ð¾ CPU ÑÐºÑ‰Ð¾ Ð½Ðµ Ð²Ð´Ð°Ð»Ð¾ÑÑ
        try:
            logger.info("Ð¡Ð¿Ñ€Ð¾Ð±Ð° fallback Ð½Ð° CPU...")
            whisper_model = WhisperModel(
                WHISPER_MODEL,
                device="cpu",
                compute_type="float32"
            )
            load_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð° Ð½Ð° CPU Ð·Ð° {load_time:.2f} ÑÐµÐºÑƒÐ½Ð´")
            return whisper_model
            
        except Exception as cpu_e:
            logger.error(f"âŒ CPU fallback Ñ‚Ð°ÐºÐ¾Ð¶ Ð½Ðµ Ð²Ð´Ð°Ð²ÑÑ: {cpu_e}")
            return None

@app.route('/health')
def health():
    """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° ÑÑ‚Ð°Ð½Ñƒ ÑÐµÑ€Ð²Ñ–ÑÑƒ"""
    global whisper_model
    
    try:
        model_loaded = whisper_model is not None
        return jsonify({
            'status': 'ok',
            'model_loaded': model_loaded,
            'model_name': WHISPER_MODEL if model_loaded else None,
            'model': WHISPER_MODEL if model_loaded else None,  # Ð´Ð»Ñ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´-ÑÑƒÐ¼Ñ–ÑÐ½Ð¾ÑÑ‚Ñ–
            'device': DEVICE,
            'compute_type': COMPUTE_TYPE,
            'timestamp': datetime.now().isoformat(),
            'service': 'atlas-whisper-large-v3'
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/transcribe', methods=['POST'])
def transcribe_audio():
    """
    Ð Ð¾Ð·Ð¿Ñ–Ð·Ð½Ð°Ð²Ð°Ð½Ð½Ñ Ð¼Ð¾Ð²Ð¸ Ð· Ð°ÑƒÐ´Ñ–Ð¾ Ñ„Ð°Ð¹Ð»Ñƒ
    
    Expected:
    - audio file in request.files['audio']
    - optional: language (uk, en, etc.)
    
    Returns:
    - JSON with transcribed text
    """
    try:
        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ð½Ð°ÑÐ²Ð½Ñ–ÑÑ‚ÑŒ Ð°ÑƒÐ´Ñ–Ð¾ Ñ„Ð°Ð¹Ð»Ñƒ
        if 'audio' not in request.files:
            return jsonify({
                'error': 'No audio file provided',
                'status': 'error'
            }), 400
        
        audio_file = request.files['audio']
        if audio_file.filename == '':
            return jsonify({
                'error': 'Empty audio file',
                'status': 'error'
            }), 400
        
        # ÐžÑ‚Ñ€Ð¸Ð¼ÑƒÑ”Ð¼Ð¾ Ð¼Ð¾Ð²Ñƒ (Ð·Ð° Ð·Ð°Ð¼Ð¾Ð²Ñ‡ÑƒÐ²Ð°Ð½Ð½ÑÐ¼ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ°)
        language = request.form.get('language', 'uk')
        
        logger.info(f"ðŸŽ¤ Transcribing audio file: {audio_file.filename}, language: {language}")
        
        # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ”Ð¼Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÑÐºÑ‰Ð¾ Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ð¾
        model = load_whisper_model()
        if model is None:
            return jsonify({
                'error': 'Whisper model not available',
                'status': 'error'
            }), 500
        
        # Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñ– Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ñ–Ñ—
        beam_size = int(request.form.get('beam_size', 5))
        word_timestamps = request.form.get('word_timestamps', 'false').lower() == 'true'
        use_vad = request.form.get('use_vad', 'true').lower() == 'true'
        
        logger.info(f"ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸: language={language}, beam_size={beam_size}, word_timestamps={word_timestamps}, use_vad={use_vad}")
        
        # Ð—Ð±ÐµÑ€Ñ–Ð³Ð°Ñ”Ð¼Ð¾ Ð°ÑƒÐ´Ñ–Ð¾ Ñƒ Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¸Ð¹ Ñ„Ð°Ð¹Ð»
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            audio_file.save(temp_file.name)
            temp_path = temp_file.name
        
        try:
            # Ð Ð¾Ð·Ð¿Ñ–Ð·Ð½Ð°Ñ”Ð¼Ð¾ Ð¼Ð¾Ð²Ñƒ Ð· Large v3
            start_time = datetime.now()
            
            # ÐÐ°Ð»Ð°ÑˆÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ VAD Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸
            transcribe_params = {
                'beam_size': beam_size,
                'language': language if language != 'auto' else None,
                'word_timestamps': word_timestamps,
                'vad_filter': use_vad
            }
            
            if use_vad:
                transcribe_params['vad_parameters'] = dict(
                    min_silence_duration_ms=2000,  # Ð—Ð±Ñ–Ð»ÑŒÑˆÑƒÑ”Ð¼Ð¾ Ð¼Ñ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ñƒ Ñ‚Ñ€Ð¸Ð²Ð°Ð»Ñ–ÑÑ‚ÑŒ Ð¼Ð¾Ð²Ñ‡Ð°Ð½Ð½Ñ
                    threshold=0.3,  # Ð—Ð½Ð¸Ð¶ÑƒÑ”Ð¼Ð¾ Ð¿Ð¾Ñ€Ñ–Ð³ Ð´ÐµÑ‚ÐµÐºÑ†Ñ–Ñ— Ð³Ð¾Ð»Ð¾ÑÑƒ Ð´Ð»Ñ Ð±Ñ–Ð»ÑŒÑˆÐ¾Ñ— Ñ‡ÑƒÑ‚Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–
                    min_speech_duration_ms=100  # ÐœÑ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ð° Ñ‚Ñ€Ð¸Ð²Ð°Ð»Ñ–ÑÑ‚ÑŒ Ð¼Ð¾Ð²Ð¸
                )
            
            segments, info = model.transcribe(temp_path, **transcribe_params)
            
            # Ð—Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð· ÑƒÑÑ–Ñ… ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ–Ð²
            transcription_segments = []
            full_text_parts = []
            
            for segment in segments:
                segment_data = {
                    'start': segment.start,
                    'end': segment.end,
                    'text': segment.text
                }
                
                if word_timestamps and hasattr(segment, 'words'):
                    segment_data['words'] = [
                        {
                            'start': word.start,
                            'end': word.end,
                            'word': word.word,
                            'probability': word.probability
                        }
                        for word in segment.words
                    ]
                
                transcription_segments.append(segment_data)
                full_text_parts.append(segment.text)
            
            full_text = ' '.join(full_text_parts).strip()
            transcription_time = (datetime.now() - start_time).total_seconds()
            
            # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ‡Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ð°Ð»Ñ–Ð´Ð½Ð¸Ð¹
            if not is_valid_transcription(full_text, info.duration):
                logger.info(f"ðŸš« Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ñ–Ð´Ñ„Ñ–Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð¾: '{full_text}'")
                return jsonify({
                    'status': 'filtered',
                    'text': '',
                    'reason': 'Suspicious or too short transcription',
                    'original_text': full_text,
                    'duration': round(info.duration, 2),
                    'transcription_time': round(transcription_time, 2),
                    'timestamp': datetime.now().isoformat()
                })
            
            logger.info(f"âœ… Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ñ–Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð° Ð·Ð° {transcription_time:.2f}Ñ: '{full_text[:100]}...'")
            
            response_data = {
                'status': 'success',
                'text': full_text,
                'language': info.language,
                'language_probability': round(info.language_probability, 4),
                'duration': round(info.duration, 2),
                'transcription_time': round(transcription_time, 2),
                'model': WHISPER_MODEL,
                'segments': transcription_segments if word_timestamps else None,
                'timestamp': datetime.now().isoformat()
            }
            
            return jsonify(response_data)
            
        finally:
            # Ð’Ð¸Ð´Ð°Ð»ÑÑ”Ð¼Ð¾ Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¸Ð¹ Ñ„Ð°Ð¹Ð»
            try:
                os.unlink(temp_path)
            except Exception as cleanup_error:
                logger.warning(f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¸Ð¹ Ñ„Ð°Ð¹Ð»: {cleanup_error}")
                
    except Exception as e:
        logger.error(f"âŒ Transcription error: {e}")
        return jsonify({
            'error': str(e),
            'status': 'error'
        }), 500

@app.route('/transcribe_blob', methods=['POST'])
def transcribe_blob():
    """
    Ð Ð¾Ð·Ð¿Ñ–Ð·Ð½Ð°Ð²Ð°Ð½Ð½Ñ Ð¼Ð¾Ð²Ð¸ Ð· Ð±Ñ–Ð½Ð°Ñ€Ð½Ð¸Ñ… Ð´Ð°Ð½Ð¸Ñ…
    
    Expected:
    - binary audio data in request.data
    - optional: language in query params
    
    Returns:
    - JSON with transcribed text
    """
    try:
        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ð½Ð°ÑÐ²Ð½Ñ–ÑÑ‚ÑŒ Ð´Ð°Ð½Ð¸Ñ…
        if not request.data:
            return jsonify({
                'error': 'No audio data provided',
                'status': 'error'
            }), 400
        
        # ÐžÑ‚Ñ€Ð¸Ð¼ÑƒÑ”Ð¼Ð¾ Ð¼Ð¾Ð²Ñƒ Ñ‚Ð° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸
        language = request.args.get('language', 'uk')
        use_vad = request.args.get('use_vad', 'true').lower() == 'true'
        
        logger.info(f"ðŸŽ¤ Transcribing audio blob ({len(request.data)} bytes), language: {language}, use_vad: {use_vad}")
        
        # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ”Ð¼Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÑÐºÑ‰Ð¾ Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ð¾
        model = load_whisper_model()
        if model is None:
            return jsonify({
                'error': 'Whisper model not available',
                'status': 'error'
            }), 500
        
        # Ð—Ð±ÐµÑ€Ñ–Ð³Ð°Ñ”Ð¼Ð¾ Ð´Ð°Ð½Ñ– Ñƒ Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¸Ð¹ Ñ„Ð°Ð¹Ð»
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            temp_file.write(request.data)
            temp_path = temp_file.name
        
        try:
            # Ð Ð¾Ð·Ð¿Ñ–Ð·Ð½Ð°Ñ”Ð¼Ð¾ Ð¼Ð¾Ð²Ñƒ
            start_time = datetime.now()
            
            # ÐÐ°Ð»Ð°ÑˆÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ VAD Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸
            transcribe_params = {
                'language': language if language != 'auto' else None,
                'vad_filter': use_vad
            }
            
            if use_vad:
                transcribe_params['vad_parameters'] = dict(
                    min_silence_duration_ms=2000,  # Ð—Ð±Ñ–Ð»ÑŒÑˆÑƒÑ”Ð¼Ð¾ Ð¼Ñ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ñƒ Ñ‚Ñ€Ð¸Ð²Ð°Ð»Ñ–ÑÑ‚ÑŒ Ð¼Ð¾Ð²Ñ‡Ð°Ð½Ð½Ñ
                    threshold=0.3,  # Ð—Ð½Ð¸Ð¶ÑƒÑ”Ð¼Ð¾ Ð¿Ð¾Ñ€Ñ–Ð³ Ð´ÐµÑ‚ÐµÐºÑ†Ñ–Ñ— Ð³Ð¾Ð»Ð¾ÑÑƒ Ð´Ð»Ñ Ð±Ñ–Ð»ÑŒÑˆÐ¾Ñ— Ñ‡ÑƒÑ‚Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–
                    min_speech_duration_ms=100  # ÐœÑ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ð° Ñ‚Ñ€Ð¸Ð²Ð°Ð»Ñ–ÑÑ‚ÑŒ Ð¼Ð¾Ð²Ð¸
                )
            
            segments, info = model.transcribe(temp_path, **transcribe_params)
            
            transcription_time = (datetime.now() - start_time).total_seconds()
            
            # Ð—Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð· ÑƒÑÑ–Ñ… ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ–Ð²
            full_text_parts = []
            for segment in segments:
                full_text_parts.append(segment.text)
            
            text = ' '.join(full_text_parts).strip()
            detected_language = info.language
            
            # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ‡Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ð°Ð»Ñ–Ð´Ð½Ð¸Ð¹
            if not is_valid_transcription(text, info.duration):
                logger.info(f"ðŸš« Blob Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ñ–Ð´Ñ„Ñ–Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð¾: '{text}'")
                return jsonify({
                    'status': 'filtered',
                    'text': '',
                    'reason': 'Suspicious or too short transcription',
                    'original_text': text,
                    'duration': round(info.duration, 2),
                    'transcription_time': transcription_time,
                    'model': WHISPER_MODEL,
                    'device': DEVICE
                })
            
            logger.info(f"âœ… Blob transcription completed in {transcription_time:.2f}s: '{text[:50]}...'")
            
            return jsonify({
                'status': 'success',
                'text': text,
                'language': detected_language,
                'transcription_time': transcription_time,
                'model': WHISPER_MODEL,
                'device': DEVICE
            })
            
        finally:
            # Ð’Ð¸Ð´Ð°Ð»ÑÑ”Ð¼Ð¾ Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¸Ð¹ Ñ„Ð°Ð¹Ð»
            try:
                os.unlink(temp_path)
            except:
                pass
                
    except Exception as e:
        logger.error(f"âŒ Blob transcription error: {e}")
        return jsonify({
            'error': str(e),
            'status': 'error'
        }), 500

@app.route('/models')
def list_models():
    """Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Whisper"""
    available_models = [
        'tiny', 'tiny.en',
        'base', 'base.en', 
        'small', 'small.en',
        'medium', 'medium.en',
        'large-v1', 'large-v2', 'large-v3'
    ]
    
    return jsonify({
        'available_models': available_models,
        'current_model': WHISPER_MODEL,
        'device': DEVICE,
        'model_loaded': whisper_model is not None
    })

def initialize_service():
    """Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ ÑÐµÑ€Ð²Ñ–ÑÑƒ Whisper"""
    logger.info("ðŸš€ Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ ATLAS Whisper Large v3 Service...")
    logger.info(f"ÐŸÐ¾Ñ€Ñ‚: {WHISPER_PORT}")
    logger.info(f"ÐœÐ¾Ð´ÐµÐ»ÑŒ: {WHISPER_MODEL}")
    logger.info(f"ÐŸÑ€Ð¸ÑÑ‚Ñ€Ñ–Ð¹: {DEVICE}")
    
    try:
        load_whisper_model()
        logger.info("âœ… Ð¡ÐµÑ€Ð²Ñ–Ñ Ñ–Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¾ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾!")
    except Exception as e:
        logger.error(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ–Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ—: {e}")
        raise

if __name__ == '__main__':
    try:
        initialize_service()
        
        logger.info(f"ðŸŒ Ð—Ð°Ð¿ÑƒÑÐº ÑÐµÑ€Ð²ÐµÑ€Ð° Ð½Ð° Ð¿Ð¾Ñ€Ñ‚Ñƒ {WHISPER_PORT}...")
        app.run(
            host='0.0.0.0',
            port=WHISPER_PORT,
            debug=False,
            threaded=True
        )
        
    except KeyboardInterrupt:
        logger.info("ðŸ›‘ Ð¡ÐµÑ€Ð²Ñ–Ñ Ð·ÑƒÐ¿Ð¸Ð½ÐµÐ½Ð¾ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ÐµÐ¼")
    except Exception as e:
        logger.error(f"âŒ ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°: {e}")
        exit(1)